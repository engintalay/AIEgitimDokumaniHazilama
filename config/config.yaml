# AI Eğitim Dokümanı Hazırlama - Konfigürasyon

# AI Model Ayarları
model:
  type: "llamacpp"  # ollama, lmstudio, openai, llamacpp
  name: ""  # llama.cpp için model adı gerekmez
  endpoint: "http://127.0.0.1:8080"  # llama.cpp default port
  #endpoint: "http://127.0.0.1:11434"  # Ollama default port
  api_key: ""  # Opsiyonel (OpenAI vb. için)
  
  # Model parametreleri
  temperature: 0.3  # Düşük = daha tutarlı, yüksek = daha yaratıcı
  max_tokens: 800  # Azaltıldı - daha hızlı cevap
  timeout: 300  # saniye (5 dakika)
  retry_attempts: 2
  retry_delay: 3  # saniye
  
  # Prompt formatı (model'e göre özelleştirilebilir)
  use_system_prompt: true  # System prompt kullan
  system_prompt: "Sen bir Türkçe eğitim dataset uzmanısın. Verilen talimatlara göre JSON formatında soru-cevap çiftleri oluşturursun."
  
  # JSON çıktı formatı
  json_mode: false  # JSON mode aktif (LM Studio bazı versiyonlarda desteklemeyebilir)
  json_wrapper: "questions"  # JSON'da wrapper key (boş ise direkt array)

# Soru üretimi ayarları
generation:
  min_questions_per_paragraph: 2  # Azaltıldı - daha hızlı
  max_questions_per_paragraph: 5  # Azaltıldı - daha hızlı
  skip_short_paragraphs: true
  min_paragraph_length: 70 # karakter (çok kısa paragrafları atla)

# Çıktı ayarları
output:
  directory: "./data/output"
  filename: "dataset.jsonl"
  append_mode: true  # Var olan dosyaya ekle
  
# Checkpoint ayarları
checkpoint:
  enabled: true
  directory: "./data/checkpoints"
  save_interval: 5  # Her 5 paragrafta bir kaydet

# İlerleme gösterimi
progress:
  show_detailed: true
  show_eta: true
  show_speed: true
  update_interval: 1  # saniye

# Loglama
logging:
  level: "INFO"  # DEBUG (detaylı), INFO, WARNING, ERROR
  file: "./data/logs/app.log"
  console: true
  show_ai_requests: true  # true yapınca Ollama istek/cevapları gösterilir
